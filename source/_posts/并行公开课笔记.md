---
title: 并行公开课笔记
date: 2022-02-22 09:18:22
tags: C++, CUDA, 并行计算
categories: 笔记

---



# 3

## 模板参数

```c++
template <int N>
void show_times(string msg){
	for (int i=0; i<N; i++){
		cout << msg << endl;
	}
}
```

`N`作为模板参数和作为函数参数，有什么区别呢？

区别在于模板参数传入的`N`是一个**编译期常量**，对于每一个不同的N，编译器都会单独生成一份代码，从而可以做单独优化。

函数参数是**运行期常量**，编译器无法自动优化。

### constexpr

`if constexpr (x)`可以指定x是编译时常量，但是有诸多限制。

1. 不能通过**运行时变量**组成的表达式决定，比如`if constexpr (x%2)`。x只能是编译期能确定的值。
2. 即使作为模板参数，传入时也必须是字面量。如果要传入变量，则变量也需要`constexpr`来修饰。如果传入的变量初始化为函数的范围值，如`constexpr bool debug = isnegative(-1)`，那么这个函数也需要`constexpr`来修饰。`constexpr`函数不能调用`non-constexpr`函数。

`constexpr`函数必须是`inline`的，不能分离声明和定义。标准库中很多函数都是`constexpr`的（如std::min），可以放心使用。

## 分离模板的声明和定义

编译器对模板的编译时**惰性**的，只有当前的.cpp文件用到了模板，该模板才会被定义。

不建议分离，违背了开闭原则。

## auto和decltype

`auto`不能用与定义类成员，很奇怪。

函数返回值也可以用`auto`来推断，但是注意：

1. 函数的多个`return`语句返回类型必须**一致**。
2. 如果没有`return`，则auto推断为`void`
3. 如果声明和实现分离了，则不能声明为`auto`

`decltype(变量名)`和`decltype(表达式)`是不同的，可以通过`decltype((a))`来强制编译器使用表达式，得到一个引用类型。 

### 万能推到decltype(auto)

如果是一个表达式，那么我们不知道它是可变引用（int &），常引用（int const &），右值引用（int &&），还是一个普通的值。

如果需要定义一个和表达式返回类型一样的变量， 可以用`decltype(auto)`来推导类型。

`decltype(auto) p = func()`

在**代理模式**中，可以用于完美转发函数返回值。

## 标准库中判断类型

## inline

现在的编译器都能自己决定要不要优化`inline`，程序员现在提供的都是**建议**

## 一致的函数

`std::is_same_v<T1, T2>`

## C++中的函数指针

C++中可以不用函数指针，参数中使用`void func(int)`就可以了，但是这样还有参数类型的限制，可以使用模板。

```C++
template <class Func>
void call_twice(Func func){
	func(0); func(1);
}
```

这种模板可以lambda表达式一起使用，如果有捕获局部变量的话（使用了**闭包**），那么最好模板参数的Func使用常引用，避免不必要的拷贝，不然会把局部变量也拷贝。

### lambda作为返回值

lambda表达式既可以作为参数，也可以作为返回值。由于lambda永远是**匿名类型**，所以必须将返回值类型声明为`auto`。

### lambda作为参数，切避免使用模板参数

lambda作为函数参数必须得使用模板，因为其匿名的特性。但是使用模板就不能分离声明和定义了。

如果有分离声明和定义的需求，可以使用`<functional>`中的`std::function<ret_type(args)>`。这是**类型擦除技术**，使用后把所有通过括号调用的函数变成虚函数。

性能不如模板，因为调用了虚函数。

如果是无捕获的lambda，可以传入为函数指针。

### lambda应用

有时我们要遍历数组查找某个特定值，如果找到了就赋值给变量，然后break。用lambda可以同时实现 break和赋值的功能。

```C++
int index = [&] {
	for(int i=0; i<arr.size(); i++)
		if(arr[i] == tofind)
			return i;
		return -1;
}();
```

类似于上述的局部函数功能，还可以写出匿名递归。

```C++
auto dfs = [&] (auto const &dfs, int index) -> void {
	dfs(dfs, next);
};
dfs(dfs, 0);
```

注意，返回值类型必须指定。

# 4. 从汇编角度看编译器优化

![image-20220223203512488](D:\code\hzhuay.github.io\source\img\image-20220223203420445.png)

x64架构下的寄存器模型，白色部分是32位系统就有的，灰色部分是x64扩充的。

32位时代只有8个通用寄存器：eax, ecx, edx, ebx, esi, edi, esp, ebp
其中esp是堆栈指针寄存器，和函数的调用与返回有关。
其中eax是用于保存返回值的寄存器。

64位时代的x86架构的通用寄存器有图中最左列的16个。其中r8到r15是新增的寄存器，给了汇编程序员更大的空间。64位相比32位机器，除了突破内存4G的限制，也有一定性能优势。比如更多的局部变量可以存到寄存器里，比存在内存里更快。

![image-20220223204038287](D:\code\hzhuay.github.io\source\img\image-20220223204038287.png)

x64和x32的通用寄存器会共用低地址位。

汇编语言大致分2种；Intel模式和AT&T模式。GCC编译出来的`.S`汇编代码是AT&T模式。开启`-O3`优化会让编译器从汇编层面进行优化，比如会发现函数传入的参数并不是都用到，就只复制用到的参数；发现参数直接当做返回值返回，就不复制到一个局部变量，而是直接复制到eax寄存器中。

编译器可以做的优化：

1. 代数简化：简化代数计算的过程
2. 常量折叠：先定义两个常量在相加，会被优化成直接将定义常量的字面量相加。
3. 写个循环从1累加到100，可以被优化到直接给寄存器写入答案
4. 如果调用了外部函数（声明和定义分离，调用时该文件找不到定义），本来应该是有一个call指令，会被优化为jump指令。
5. 如果调用了内部函数（调用时直接可以看到定义），且函数体足够简单的话，可以直接优化为内联函数。
6. 合并写入。在数组两个相邻的位置写入两个32位的int，可以合并为向一个64位的寄存器写入。
7. 数组清零：手动写for循环对数组清零，会被优化为标准库函数`memset`
8. SIMD加速：假设有一个循环将`a[i]=i`，那么编译器会将循环的步长设为4，每次对4个int进行赋值。如果数组的长度不是4的倍数，会做边界特判，剩余的部分逐个写入。（所以推荐数组大小都是4的整数倍，或者先将数组长度处理为`n=n/4*4`）

编译器的优化能力是有限度的，很难对储存在堆上的变量优化（往往是复杂的容器和对象），容易对存储在栈上的优化（往往是简单的数值）。

`volatile`会禁止编译器优化某个变量的读写操作，防止优化编译器把变量从内存装入CPU寄存器中这样系统总是重新从它所在的内存读取数据，保证了多线程下一定使用内存中的变量，而不会同时使用寄存器和内存中的变量。

## __restrict关键字

```C++
void func(int *a, int *b, int *c) {
	*c = *a;
	*c = *b;
}
```

这段代码看起来很好优化，因为第一条语句时没有用的，但是实际上编译器并不会优化，因为有潜在的风险。加入调用者是这么调用函数的：`func(&a, &b, &b)`。看起来函数的效果是把第二参数的值赋给第三参数，但是这样调用会导致第一参数赋给了第三参数。，这就是**指针别名现象**。看起来函数的三个参数没有关系，但是实际调用的时候，他们可能指向同一个地址。编译器为了保证正确，不敢去优化这段代码。

如果我们可以保证这三个参数绝对不会相等，需要加上`__restrict`关键字，将函数定义为：

```C++ 
void func(int *__restrict a, int *__restrict b, int *__restrict c);
```

这样编译器就可以放心优化。

实际上，`__restrict`只需要加在具有写入访问的指针上，就可以优化成功，同样可以用`const`来禁止写入访问。因此，所有非`const`的指针都声明为`__restrict`就行了。

`__restrict`是C99标准，但不是C++标准。

## 循环中的矢量化

```C++
void func(float *a, float *b){
	for(int i = 0; i < 1024; i++) {
		a[i] = b[i] + 1;
	}
}
```

这段代码我们认为可以进行SIMD优化，但是编译器却会生成两个版本，因为它担心数组a和b有重叠，这样在改变a的时候也会改变b。因此编译器会对指针进行判断，看两个数组是否重叠，来决定调用哪个版本。这样不仅多了判断的消耗，还让代码膨胀。

这个问题也可以用`__restrict`来优化。

# 5. C++11多线程编程

## 时间处理

C语言处理时间依赖`<time.h>`库，有诸多问题：

1. 很不灵活。用`long`时间戳来表示从1970年开始过了多少秒，可以对这个值进行无意义的运算。`sleep`只能以秒为单位，想要睡眠毫秒级只能用Linux特有的API`usleep`。
2. C语言原始API没有类型区分，导致很容易弄错单位，混淆**时间点**和**时间段**。

C++11引入时间标准库`std::chrono`。

利用C++强类型的特点，明确区分时间点和时间段，区分不同时间单位。
比如两个时间点类型相减，得到的就是时间段类型。

## 多线程

C语言使用pthread库进行多线程编程，但是pthread的函数式编程不符合面向对象思想，C++11开始提供了`std::thread`，封装了pthread，从语言级别提供了多线程的支持。

`std::thread`的构造函数的参数可以是**任意**lambda表达式。构造完成后即开始运行。

线程作为对象，遵循RAII原则，有自己的析构函数，删除了拷贝构造和拷贝赋值函数，提供了移动构造/赋值函数。当thread需要被析构时，对应的pthread线程也会被销毁。

`detach`函数会分离thread对象与pthread线程，使线程的生命周期不再由`std::thread`对象管理，而是线程退出后自动销毁自己。

### 多个线程都结束后才退出

```C++
class ThreadPool{
	vector<thread> m_pool;
public:
	void push_back(thread thr) {
		m_pool.push_back(move(thr));
	}
	~ThreadPool() {
		for (auto &t: m_pool) t.join();
	}
};
ThreadPool tpool;
```

定义一个全局进程池，其声明周期和main函数一致。在main函数结束时，tpool的析构函数会被自动调用，将所有进程都join，这样就可以等待他们全部结束。

## 异步

`std::async`接收一个带返回值的lambda，自身返回一个`std::future<T>`对象。lambda的函数体将在**另一个线程**里执行。

future的含义是由于这个lambda是异步执行的，所以这个返回值目前还没有，但将来一定会有。调用future的get()方法可以获得返回值。如果还没执行完，则会阻塞在这里。

wait()函数也有类似的功能，会阻塞等待lambda执行完，但是没有返回值。

`wait_for()`可以指定一个最长等待时间，返回一个`future_status::timeout`或`future_status::ready`表示是否完成。

### 推迟执行

`std::async`的第一个参数可以设为`std::launch::deferred`，这样lambda就不会另起一个线程来执行，而是**推迟**到get()调用时才在主线程中执行，因此只是函数式编程范式意义上的异步，可以实现**惰性求值**。

### 底层实现

`std::async`底层实现基于`std::promise`。如果不想让`std::async`自动创建线程，想手动创建，可以创建一个`std::promise`对象。把lambda的返回值处改为调用`std::promise`的`set_value()`，然后在主线程里调用`get_future()`获取其`std::future`对象，再调用`get()`。

## 互斥量

`std::mutex`有lock()和unlock()两种操作。

- lock：获取锁，如果已经上锁则阻塞等待
- try_lock：尝试上锁，返回bool表示成功或失败
- `std::timed_mutex`的try_lock_for：等到一段时间，超时返回false。

### 复合RAII的互斥锁

如果将互斥锁视为资源，上锁和解锁分别视为获取和释放，那么互斥锁也可以通过class来自动管理。

`std::lock_guard`就是这样一个工具类，会在构造函数里传入一个`std::mutex`并调用lock，析构函数里调用unlock。

这样的类可以用空花括号来规定声明周期。把需要上锁的代码都放在一个花括号内。

#### 自由度更高的锁

`std::lock_guard`严格按照生命周期来解锁，但是如果我们需要**提前unlock**，可以使用`std::unique_lock`，它额外储存了一个`flag`表示是否已经被释放，在**析构**时检测这个`flag`，如果已经被释放则不调用unlock。

`std::unique_lock`的构造函数还可以有一个额外的参数`std::defer_lock`，如果指定了该参数，那么`unique_lock`就不会在构造函数时上锁，而是需要**手动上锁**。

`std::unique_lock`也可以用`std::try_to_lock`作为构造函数，这样就要调用try_lock()上锁和用`owns_lock()`判断是否上锁成功。

如果`std::unique_lock`或者`std::lock_guard`传入的参数mutex已经上锁，要在构造函数传入`std::adopt_lock`，那么依然可以自动解锁。

#### 概念（鸭子类型）

`std::unique_lock`也有lock和unlock函数，所以也可以作为`std::lock_guard`的参数。

只要具有特定名字的成员函数，就判断一个类是否满足某些功能，这种机制在Python中称为**鸭子类型**，在C++中称为**概念**。比起虚函数和动态多态的接口抽象，concept使实现和接口更加解耦，且没有性能损失。

## 死锁

1. **互斥条件**：进程对所需求的资源具有排他性，若有其他进程请求该资源，请求进程只能等待。
2. **不剥夺条件**：进程在所获得的资源未释放前，不能被其他进程强行夺走，只能自己释放。
3. **请求和保持条件**：进程当前所拥有的资源在进程请求其他新资源时，由该进程继续占有。
4. **循环等待条件**：存在一种进程资源循环等待链，链中每个进程已获得的资源同时被链中下一个进程所请求。

避免死锁最简单的方法：

1. 永远不要同时持有两个锁。
2. 保证不同进程上锁的顺序一致。
3. 使用`std::lock(mtx1, mtx2, ...)`，可以对多个mutex上锁且保证不会死锁。解锁则按照任意顺序对mutex调用unlock即可。

就和mutex有RAII版本的`std::lock_guard`一样，`std::lock`的RAII版本是 `std::scoped_lock`

### 单线程也可以死锁

死锁不一定发生在并发环境中，单线程中调用了一个会加锁的函数，如果这个函数又调用了自己，那么就会死锁。

解决这种情况最好是不要在该函数内上锁，并在文档中说明：

> 该函数不是线程安全的，调用本函数前请先保证mutex已经上锁。

如果代码已经无法改动，可以改用`std::recursive_mutex`，它会自动判断是不会是在**同一线程**中多次对同一个mutex上锁，如果是则让计数器加一，解锁则减一，减到0才真正解锁。缺点是相比普通的`std::mutex`有性能损失。

## 读写锁

`std::shared_mutex`是读写锁。

lock和unlock对应写锁，有修改数据的需求。`lock_shared`和`unlock_shared`对应读锁。

`std::shared_lock`是符合RAII的`shared_mutex`，不同于`unique_lock`会调用lock，`shared_lock`调用的是`lock_shared`。

## 访问者模式

```C++
class MTVector {
	std::vector<int> m_arr;
	std::mutex m_mtx;
public:
	class Accessor {
		MTVector &m_that;
        std::unique_lock<std::mutex> m_guard;
    public:
        Accessor(MTVector &that): m_that(that), m_guard(that.m_mtx) {}
        void push_back(int val) const {
            return m_that.arr.push_back(val);
        }
        size_t size() const {
			return m_that.m_arr.size();
        }
	}
    Accessor access() {
		return {*this};
    }
};
```

访问者模式可以很好地为了多线程上锁服务。如果我们自定义了一个线程安全的vector，在每次操作时都加锁，那么有很大的性能开销。

使用时只需要`auto axr = arr.access();`。访问者模式分离了数据的存储和访问，在需要访问时只加一次锁。

## 条件变量

等待特定条件，满足后被唤醒。`std::condition_variable`就是条件变量，必须和`std::unique_lock<std::mutex>`一起使用。

`wait(lck)`会使线程陷入等待。`notify_one()`会唤醒那个陷入等待的线程。 `notify_all()`会唤醒所有等待该条件变量的线程。

`wait(lck, lambda)`可以额外指定一个lambda作为参数，只有当返回值为true时才真正唤醒。这样就可以实现生产者-消费者模式。

## 原子操作

一个`counter += i`在CPU看来会变成3个指令：

1. 读取counter变量到rax寄存器
2. rax寄存器的值加上1
3. 把rax写入到counter变量

即使编译器优化为`add [counter], 1`也没用，因为现代CPU为了高效，会把一条汇编指令拆分为很多微指令，然后可能会重排、乱序执行、并行执行。

保证操作原子性的暴力解决方案是用mutex上锁，但是mutex是操作系统提供的，太过**重量级**，它会让线程被挂起，从而需要通过系统调用，进入**内核态**，调度到其他线程执行，有很大开销。

用`atomic`是更高效，更轻量的，它会被编译器转换为专门的硬件指令。

CPU在识别到该指令时，会锁住内存总线，放弃乱序执行等优化策略（将该指令视为一个同步点，强制同步之前所有的内存操作），从而保证该操作是**原子**的。

对于程序员而言，只需要把`int`改为`atomic<int>`即可，不需要mutex那样手动控制锁，也更加直观。

### 注意运算符

注意，不是所有的运算都保证原子性，只有`+=`，`-=`，`&=`，`|=`，`^=`，`++`，`--`可以。

用`=`赋值也不能保证原子，需要调用`store(val)`。`exchange`会在赋值的同时返回旧值。

除了调用重载运算符，还可以调用函数。`fatch_add`不仅能执行加法，还可以返回**旧值**。
