---
title: 并行公开课笔记
date: 2022-02-22 09:18:22
tags: C++, CUDA, 并行计算
categories: 笔记

---



# 3

## 模板参数

```c++
template <int N>
void show_times(string msg){
	for (int i=0; i<N; i++){
		cout << msg << endl;
	}
}
```

`N`作为模板参数和作为函数参数，有什么区别呢？

区别在于模板参数传入的`N`是一个**编译期常量**，对于每一个不同的N，编译器都会单独生成一份代码，从而可以做单独优化。

函数参数是**运行期常量**，编译器无法自动优化。

### constexpr

`if constexpr (x)`可以指定x是编译时常量，但是有诸多限制。

1. 不能通过**运行时变量**组成的表达式决定，比如`if constexpr (x%2)`。x只能是编译期能确定的值。
2. 即使作为模板参数，传入时也必须是字面量。如果要传入变量，则变量也需要`constexpr`来修饰。如果传入的变量初始化为函数的范围值，如`constexpr bool debug = isnegative(-1)`，那么这个函数也需要`constexpr`来修饰。`constexpr`函数不能调用`non-constexpr`函数。

`constexpr`函数必须是`inline`的，不能分离声明和定义。标准库中很多函数都是`constexpr`的（如std::min），可以放心使用。

## 分离模板的声明和定义

编译器对模板的编译时**惰性**的，只有当前的.cpp文件用到了模板，该模板才会被定义。

不建议分离，违背了开闭原则。

## auto和decltype

`auto`不能用与定义类成员，很奇怪。

函数返回值也可以用`auto`来推断，但是注意：

1. 函数的多个`return`语句返回类型必须**一致**。
2. 如果没有`return`，则auto推断为`void`
3. 如果声明和实现分离了，则不能声明为`auto`

`decltype(变量名)`和`decltype(表达式)`是不同的，可以通过`decltype((a))`来强制编译器使用表达式，得到一个引用类型。 

### 万能推到decltype(auto)

如果是一个表达式，那么我们不知道它是可变引用（int &），常引用（int const &），右值引用（int &&），还是一个普通的值。

如果需要定义一个和表达式返回类型一样的变量， 可以用`decltype(auto)`来推导类型。

`decltype(auto) p = func()`

在**代理模式**中，可以用于完美转发函数返回值。

## 标准库中判断类型

## inline

现在的编译器都能自己决定要不要优化`inline`，程序员现在提供的都是**建议**

## 一致的函数

`std::is_same_v<T1, T2>`

## C++中的函数指针

C++中可以不用函数指针，参数中使用`void func(int)`就可以了，但是这样还有参数类型的限制，可以使用模板。

```C++
template <class Func>
void call_twice(Func func){
	func(0); func(1);
}
```

这种模板可以lambda表达式一起使用，如果有捕获局部变量的话（使用了**闭包**），那么最好模板参数的Func使用常引用，避免不必要的拷贝，不然会把局部变量也拷贝。

### lambda作为返回值

lambda表达式既可以作为参数，也可以作为返回值。由于lambda永远是**匿名类型**，所以必须将返回值类型声明为`auto`。

### lambda作为参数，切避免使用模板参数

lambda作为函数参数必须得使用模板，因为其匿名的特性。但是使用模板就不能分离声明和定义了。

如果有分离声明和定义的需求，可以使用`<functional>`中的`std::function<ret_type(args)>`。这是**类型擦除技术**，使用后把所有通过括号调用的函数变成虚函数。

性能不如模板，因为调用了虚函数。

如果是无捕获的lambda，可以传入为函数指针。

### lambda应用

有时我们要遍历数组查找某个特定值，如果找到了就赋值给变量，然后break。用lambda可以同时实现 break和赋值的功能。

```C++
int index = [&] {
	for(int i=0; i<arr.size(); i++)
		if(arr[i] == tofind)
			return i;
		return -1;
}();
```

类似于上述的局部函数功能，还可以写出匿名递归。

```C++
auto dfs = [&] (auto const &dfs, int index) -> void {
	dfs(dfs, next);
};
dfs(dfs, 0);
```

注意，返回值类型必须指定。

# 5. C++11多线程编程

## 时间处理

C语言处理时间依赖`<time.h>`库，有诸多问题：

1. 很不灵活。用`long`时间戳来表示从1970年开始过了多少秒，可以对这个值进行无意义的运算。`sleep`只能以秒为单位，想要睡眠毫秒级只能用Linux特有的API`usleep`。
2. C语言原始API没有类型区分，导致很容易弄错单位，混淆**时间点**和**时间段**。

C++11引入时间标准库`std::chrono`。

利用C++强类型的特点，明确区分时间点和时间段，区分不同时间单位。
比如两个时间点类型相减，得到的就是时间段类型。

## 多线程

C语言使用pthread库进行多线程编程，但是pthread的函数式编程不符合面向对象思想，C++11开始提供了`std::thread`，封装了pthread，从语言级别提供了多线程的支持。

`std::thread`的构造函数的参数可以是**任意**lambda表达式。构造完成后即开始运行。

线程作为对象，遵循RAII原则，有自己的析构函数，删除了拷贝构造和拷贝赋值函数，提供了移动构造/赋值函数。当thread需要被析构时，对应的pthread线程也会被销毁。

`detach`函数会分离thread对象与pthread线程，使线程的生命周期不再由`std::thread`对象管理，而是线程退出后自动销毁自己。

### 多个线程都结束后才退出

```C++
class ThreadPool{
	vector<thread> m_pool;
public:
	void push_back(thread thr) {
		m_pool.push_back(move(thr));
	}
	~ThreadPool() {
		for (auto &t: m_pool) t.join();
	}
};
ThreadPool tpool;
```

定义一个全局进程池，其声明周期和main函数一致。在main函数结束时，tpool的析构函数会被自动调用，将所有进程都join，这样就可以等待他们全部结束。

## 异步

`std::async`接收一个带返回值的lambda，自身返回一个`std::future<T>`对象。lambda的函数体将在**另一个线程**里执行。

future的含义是由于这个lambda是异步执行的，所以这个返回值目前还没有，但将来一定会有。调用future的get()方法可以获得返回值。如果还没执行完，则会阻塞在这里。

wait()函数也有类似的功能，会阻塞等待lambda执行完，但是没有返回值。

`wait_for()`可以指定一个最长等待时间，返回一个`future_status::timeout`或`future_status::ready`表示是否完成。

### 推迟执行

`std::async`的第一个参数可以设为`std::launch::deferred`，这样lambda就不会另起一个线程来执行，而是**推迟**到get()调用时才在主线程中执行，因此只是函数式编程范式意义上的异步，可以实现**惰性求值**。

### 底层实现

`std::async`底层实现基于`std::promise`。如果不想让`std::async`自动创建线程，想手动创建，可以创建一个`std::promise`对象。把lambda的返回值处改为调用`std::promise`的`set_value()`，然后在主线程里调用`get_future()`获取其`std::future`对象，再调用`get()`。

## 互斥量

`std::mutex`有lock()和unlock()两种操作。

- lock：获取锁，如果已经上锁则阻塞等待
- try_lock：尝试上锁，返回bool表示成功或失败
- `std::timed_mutex`的try_lock_for：等到一段时间，超时返回false。

### 复合RAII的互斥锁

如果将互斥锁视为资源，上锁和解锁分别视为获取和释放，那么互斥锁也可以通过class来自动管理。

`std::lock_guard`就是这样一个工具类，会在构造函数里传入一个`std::mutex`并调用lock，析构函数里调用unlock。

这样的类可以用空花括号来规定声明周期。把需要上锁的代码都放在一个花括号内。

#### 自由度更高的锁

`std::lock_guard`严格按照生命周期来解锁，但是如果我们需要**提前unlock**，可以使用`std::unique_lock`，它额外储存了一个`flag`表示是否已经被释放，在**析构**时检测这个`flag`，如果已经被释放则不调用unlock。

`std::unique_lock`的构造函数还可以有一个额外的参数`std::defer_lock`，如果指定了该参数，那么`unique_lock`就不会在构造函数时上锁，而是需要**手动上锁**。

`std::unique_lock`也可以用`std::try_to_lock`作为构造函数，这样就要调用try_lock()上锁和用`owns_lock()`判断是否上锁成功。

如果`std::unique_lock`或者`std::lock_guard`传入的参数mutex已经上锁，要在构造函数传入`std::adopt_lock`，那么依然可以自动解锁。

#### 概念（鸭子类型）

`std::unique_lock`也有lock和unlock函数，所以也可以作为`std::lock_guard`的参数。

只要具有特定名字的成员函数，就判断一个类是否满足某些功能，这种机制在Python中称为**鸭子类型**，在C++中称为**概念**。比起虚函数和动态多态的接口抽象，concept使实现和接口更加解耦，且没有性能损失。

## 死锁

1. **互斥条件**：进程对所需求的资源具有排他性，若有其他进程请求该资源，请求进程只能等待。
2. **不剥夺条件**：进程在所获得的资源未释放前，不能被其他进程强行夺走，只能自己释放。
3. **请求和保持条件**：进程当前所拥有的资源在进程请求其他新资源时，由该进程继续占有。
4. **循环等待条件**：存在一种进程资源循环等待链，链中每个进程已获得的资源同时被链中下一个进程所请求。

避免死锁最简单的方法：

1. 永远不要同时持有两个锁。
2. 保证不同进程上锁的顺序一致。
3. 使用`std::lock(mtx1, mtx2, ...)`，可以对多个mutex上锁且保证不会死锁。解锁则按照任意顺序对mutex调用unlock即可。

就和mutex有RAII版本的`std::lock_guard`一样，`std::lock`的RAII版本是 `std::scoped_lock`

### 单线程也可以死锁

死锁不一定发生在并发环境中，单线程中调用了一个会加锁的函数，如果这个函数又调用了自己，那么就会死锁。

解决这种情况最好是不要在该函数内上锁，并在文档中说明：

> 该函数不是线程安全的，调用本函数前请先保证mutex已经上锁。

如果代码已经无法改动，可以改用`std::recursive_mutex`，它会自动判断是不会是在**同一线程**中多次对同一个mutex上锁，如果是则让计数器加一，解锁则减一，减到0才真正解锁。缺点是相比普通的`std::mutex`有性能损失。

## 读写锁

`std::shared_mutex`是读写锁。

lock和unlock对应写锁，有修改数据的需求。`lock_shared`和`unlock_shared`对应读锁。

`std::shared_lock`是符合RAII的`shared_mutex`，不同于`unique_lock`会调用lock，`shared_lock`调用的是`lock_shared`。

## 访问者模式

```C++
class MTVector {
	std::vector<int> m_arr;
	std::mutex m_mtx;
public:
	class Accessor {
		MTVector &m_that;
        std::unique_lock<std::mutex> m_guard;
    public:
        Accessor(MTVector &that): m_that(that), m_guard(that.m_mtx) {}
        void push_back(int val) const {
            return m_that.arr.push_back(val);
        }
        size_t size() const {
			return m_that.m_arr.size();
        }
	}
    Accessor access() {
		return {*this};
    }
};
```

访问者模式可以很好地为了多线程上锁服务。如果我们自定义了一个线程安全的vector，在每次操作时都加锁，那么有很大的性能开销。

使用时只需要`auto axr = arr.access();`。访问者模式分离了数据的存储和访问，在需要访问时只加一次锁。

## 条件变量

等待特定条件，满足后被唤醒。`std::condition_variable`就是条件变量，必须和`std::unique_lock<std::mutex>`一起使用。

`wait(lck)`会使线程陷入等待。`notify_one()`会唤醒那个陷入等待的线程。 `notify_all()`会唤醒所有等待该条件变量的线程。

`wait(lck, lambda)`可以额外指定一个lambda作为参数，只有当返回值为true时才真正唤醒。这样就可以实现生产者-消费者模式。

## 原子操作

一个`counter += i`在CPU看来会变成3个指令：

1. 读取counter变量到rax寄存器
2. rax寄存器的值加上1
3. 把rax写入到counter变量

即使编译器优化为`add [counter], 1`也没用，因为现代CPU为了高效，会把一条汇编指令拆分为很多微指令，然后可能会重排、乱序执行、并行执行。

保证操作原子性的暴力解决方案是用mutex上锁，但是mutex是操作系统提供的，太过**重量级**，它会让线程被挂起，从而需要通过系统调用，进入**内核态**，调度到其他线程执行，有很大开销。

用`atomic`是更高效，更轻量的，它会被编译器转换为专门的硬件指令。

CPU在识别到该指令时，会锁住内存总线，放弃乱序执行等优化策略（将该指令视为一个同步点，强制同步之前所有的内存操作），从而保证该操作是**原子**的。

对于程序员而言，只需要把`int`改为`atomic<int>`即可，不需要mutex那样手动控制锁，也更加直观。

### 注意运算符

注意，不是所有的运算都保证原子性，只有`+=`，`-=`，`&=`，`|=`，`^=`，`++`，`--`可以。

用`=`赋值也不能保证原子，需要调用`store(val)`。`exchange`会在赋值的同时返回旧值。

除了调用重载运算符，还可以调用函数。`fatch_add`不仅能执行加法，还可以返回**旧值**。
